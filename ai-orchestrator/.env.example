# AI Orchestrator Environment Configuration
# Copy this file to .env and fill in the values
#
# For Docker deployment, these values are set in docker-compose.yml
# For local development, copy this file to .env and configure

# =============================================================================
# Application Settings
# =============================================================================

# Application name (default: AI Orchestrator)
APP_NAME=AI Orchestrator

# Environment: development, staging, production
# - development: Human-readable logs, debug mode
# - production: JSON logs, optimized for monitoring
ENVIRONMENT=development

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# =============================================================================
# Gemini API Configuration (REQUIRED)
# =============================================================================

# Google Gemini API key
# Get your API key from: https://aistudio.google.com/app/apikey
# This is REQUIRED - the application will not start without it
GEMINI_API_KEY=your_gemini_api_key_here

# Gemini model for chat and intent recognition (default: gemini-2.5-pro)
# Used for complex reasoning and structured output
GEMINI_MODEL_CHAT=gemini-2.5-pro

# Gemini model for fast responses (default: gemini-2.5-flash)
# Used for quick response generation
GEMINI_MODEL_FAST=gemini-2.5-flash

# Gemini Imagen 3 model for image generation (default: imagen-3.0-generate-002)
# Used for AI-powered ad creative generation
GEMINI_MODEL_IMAGEN=imagen-3.0-generate-002

# =============================================================================
# Web Platform Integration (REQUIRED)
# =============================================================================

# URL of the Web Platform backend
# - Local development: http://localhost:8000
# - Docker: http://backend:8000
WEB_PLATFORM_URL=http://localhost:8000

# Service token for authentication with Web Platform
# This token must match WEB_PLATFORM_SERVICE_TOKEN in backend/.env
# Generate with: python -c "import secrets; print(secrets.token_urlsafe(32))"
# This is REQUIRED - the application will not start without it
WEB_PLATFORM_SERVICE_TOKEN=your_service_token_here

# =============================================================================
# Redis Configuration
# =============================================================================

# Redis URL for state persistence and caching
# - Local development: redis://localhost:6379/3
# - Docker: redis://redis:6379/3
# Database 3 is used to avoid conflicts with backend (db 0)
REDIS_URL=redis://localhost:6379/3

# Maximum connections in Redis connection pool
REDIS_MAX_CONNECTIONS=10

# Redis socket timeout in seconds
REDIS_SOCKET_TIMEOUT=5.0

# Redis socket connect timeout in seconds
REDIS_SOCKET_CONNECT_TIMEOUT=5.0

# =============================================================================
# Performance Settings
# =============================================================================

# Maximum concurrent requests the service can handle
MAX_CONCURRENT_REQUESTS=100

# Request timeout in seconds (for MCP calls and LLM requests)
REQUEST_TIMEOUT=60

# =============================================================================
# Docker Deployment Notes
# =============================================================================
#
# When running with docker-compose, the following values are overridden:
# - WEB_PLATFORM_URL=http://backend:8000
# - REDIS_URL=redis://redis:6379/3
#
# Required environment variables in docker-compose.yml:
# - GEMINI_API_KEY (from host environment or .env in project root)
# - WEB_PLATFORM_SERVICE_TOKEN (shared with backend service)
